{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll5B6dINCJLj"
      },
      "outputs": [],
      "source": [
        "# 먼저 텐서플로우 다운받고 mnist 다운받고 준비를 한다.\n",
        "# 2NN 모델을 설계한다. K는 2~3개 정도만 설정 1Epoch만 돌리고 !!!Weight를 Server로 보낸다.!!! 서버는 W_(t+1)=W_t - g_k    //Fed_SGD,\n",
        "# 나중에는 클라이언트에서 여러 epoch로 돌리고 Weight를 Server로 보낸다. 서버는 W_(t+1)=W_t - g_k // Fed_AVG\n",
        "# 당연히 Communication cost는 AVG가 적을 것, AVG가 정확성이 따라올 수 있느냐를 중점으로 확인.\n",
        "# 가장 먼저 서버모델을 만들고(이니셜라이징), 포문?(확실치 않은 이유가 포문 돌때마다 처음으로 초기화될까봐 겁남.)\n",
        "# 전체 포문 안에 클라이언트1,2 돌리고 그 2개의 w를 산술평균?(일단 나중에 가중산술평균할겨) 마지막에 서버 모델 w에 덮어씌우고\n",
        "# 근데 Non-IID 로 MNIST는 어떻게 나누지?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' 8/29 \n",
        "    AVG로 구현하기 dd\n",
        "    1round 마다 server가 클라이언트한테 나눠주기 구현 dd\n",
        "    2NN말고 CNN으로 구현하기 dd\n",
        "    MNIST 전부 분류하고 랜덤하게 몇개씩 뽑고 뽑을 때 겹치지 않게\n",
        "    시각적으로 보이게 히스토그램?\n",
        "    각 클라이언트들이 에포크 증가할때 정확도가 증가하는지?\n",
        "    클라이언트가 N개일 때 자동화 어떻게 할 것인지..\n",
        "    논문에서는 클라이언트가 100이다.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cnt0dhsmRZ_",
        "outputId": "18eea383-1e0e-43ae-a9d2-b3e350c78d33"
      },
      "outputs": [],
      "source": [
        "%pip install matplotlib\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "C_epoch=3  # 각 클라이언트마다 몇 에포크 돌릴지\n",
        "S_round=10  #총 라운드 수\n",
        "#\n",
        "\n",
        "#\n",
        "\n",
        "#\n",
        "\n",
        "#데이터(MNIST) 전처리\n",
        "# MNIST 데이터를 불러옵니다.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 차원 변환 후, 테스트셋과 학습셋으로 나눔\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "##서버 모델 이니셜라이징\n",
        "# 모델 구조를 설정\n",
        "'''\n",
        "'''\n",
        "\n",
        "server_model = Sequential()\n",
        "server_model.add(Conv2D(32, kernel_size=(5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "server_model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "server_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#server_model.add(Dropout(0.25))\n",
        "server_model.add(Flatten())\n",
        "server_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#서버 레이어들 정보 요약\n",
        "server_model.summary()                                                \n",
        "\n",
        "# 모델 실행 환경을 설정\n",
        "server_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 최적화를 위한 설정 구간\n",
        "serverpath=\"./MNIST_MLP_0.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=serverpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# 모델 실행\n",
        "server_history = server_model.fit(x_train[0:2], y_train[0:2], validation_split=0.25, epochs=1, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer]) # 최대한 학습 안할려고 2개만 학습시킴..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JePAhOHmRL7",
        "outputId": "feb2a0c0-b90c-4f8a-819b-c6d8e70e05ba"
      },
      "outputs": [],
      "source": [
        "##클라이언트1 모델 이니셜라이징\n",
        "# 모델 구조를 설정\n",
        "\n",
        "\n",
        "client_1_model = Sequential()\n",
        "client_1_model.add(Conv2D(32, kernel_size=(5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "client_1_model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "client_1_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#client_1_model.add(Dropout(0.25))\n",
        "client_1_model.add(Flatten())\n",
        "client_1_model.add(Dense(10, activation='softmax'))\n",
        "client_1_model.summary()                                                #서버 레이어들 정보 요약\n",
        "\n",
        "# 모델 실행 환경을 설정\n",
        "client_1_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 최적화를 위한 설정 구간\n",
        "client_1path=\"./MNIST_MLP_1.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=client_1path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "#처음 서버가 클라이언트한테 나눠주는 것\n",
        "array_temp=server_model.get_weights()\n",
        "client_1_model.set_weights(array_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJrjib8QmRB-",
        "outputId": "b441985d-1174-402d-c17d-0f7ff36c3d73"
      },
      "outputs": [],
      "source": [
        "##클라이언트2 모델 이니셜라이징\n",
        "# 모델 구조를 설정\n",
        "client_2_model = Sequential()\n",
        "client_2_model.add(Conv2D(32, kernel_size=(5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "client_2_model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "client_2_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#client_2_model.add(Dropout(0.25))\n",
        "client_2_model.add(Flatten())\n",
        "client_2_model.add(Dense(10, activation='softmax'))\n",
        "client_2_model.summary()    #서버 레이어들 정보 요약\n",
        "\n",
        "# 모델 실행 환경을 설정\n",
        "client_2_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 최적화를 위한 설정 구간\n",
        "client_2path=\"./MNIST_MLP_2.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=client_2path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "\n",
        "#처음 서버가 클라이언트한테 나눠주는 것\n",
        "array_temp=server_model.get_weights()\n",
        "client_2_model.set_weights(array_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dhWTe_De9wy",
        "outputId": "b50b294a-7604-42c2-91bb-8b000de02076"
      },
      "outputs": [],
      "source": [
        "#클라이언트 w를 산술평균해서 서버 w에 덮어 씌우기.\n",
        "history_temp=[[],[]]\n",
        "\n",
        "for i in range(0,S_round):\n",
        "  #각 클라이언트들마다 computations\n",
        "  client_1_history = client_1_model.fit(x_train[0:10000], y_train[0:10000], validation_split=0.25, epochs=C_epoch, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer]) # B : 200\n",
        "  client_2_history = client_2_model.fit(x_train[10000:20000], y_train[10000:20000], validation_split=0.25, epochs=C_epoch, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer]) # B : 200\n",
        "  \n",
        "  #각 클라이언트들의 w를 산술평균해서 서버에다가 주는 과정  \n",
        "  array_temp=client_1_model.get_weights()\n",
        "  array_temp = (np.array(client_1_model.get_weights()) + np.array(client_2_model.get_weights()))/2.0\n",
        "  server_model.set_weights(array_temp)\n",
        "  \n",
        "  #1round마다 서버에 모여진 w를 다시 클라이언트한테 주는 것\n",
        "  array_temp=server_model.get_weights()\n",
        "  client_1_model.set_weights(array_temp)\n",
        "  client_2_model.set_weights(array_temp)\n",
        "\n",
        "  #서버의 1round마다의 데이터들의 히스토리를 모으는 과정\n",
        "  history_temp[1].append(server_model.evaluate(x_test, y_test)[1])\n",
        "  print(str(i+1)+\"th Test Accuracy: %.4f\" % (history_temp[-1][-1]))\n",
        "  history_temp[0].append(server_model.evaluate(x_train[0:20000], y_train[0:20000])[1])\n",
        "  print(str(i+1)+\"th Train Accuracy: %.4f\" % (history_temp[0][-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "US9iJu4rlKDz",
        "outputId": "41927ab2-e6cf-48d2-e1ab-b09d3d211921"
      },
      "outputs": [],
      "source": [
        "# 테스트 정확도\n",
        "print(\"\\n Test Accuracy: %.4f\" % (server_model.evaluate(x_test, y_test)[1]))\n",
        "# 검증셋과 학습셋의 오차를 저장\n",
        "y_vloss = history_temp[1] #server_history.history['val_loss']\n",
        "y_loss = history_temp[0]  #server_history.history['loss']\n",
        "\n",
        "# 그래프로 표현\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
        "\n",
        "# 그래프에 그리드, 레이블\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('round')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#keras model에서 가중치(weights) 가져오기\n",
        "\n",
        ">`Model.get_weights()`\n",
        "\n",
        "return:모델의 가중치 배열\n",
        "\n",
        "#Keras model에 가중치(weights) 설정하기\n",
        ">`Model.set_weights(weights)`\n",
        "\n",
        "argument:\n",
        " - weights : numpy 배열의 가중치\n",
        "\n",
        "#Keras model의 가중치(weights) 파일로 저장하기\n",
        ">`Model.save_weights(filepath, overwrite=True)`\n",
        "\n",
        "arguments:\n",
        " - filepath : 저장할 파일 경로, HDF5 형식으로 저장된다.\n",
        " - overwrite : 덮어쓰기 여부\n",
        "\n",
        "#파일에서 Keras model 가중치(weights) 불러와 설정하기\n",
        "> `Model.load_weights(filepath, by_name=False, skip_mismatch=False, reshpae=False)`\n",
        "\n",
        "arguments:\n",
        " - filepath : 가중치 파일의 경로\n",
        " - by_name : 이름 또는 토폴로지 순서로 가중치를 로드 할지 여부를 나타낸다.\n",
        " - skip_mismath : 가중치 개수나 모양이 일치하지 않는 레이어를 건너 뛸지에 대한 여부를 나타낸다. (by_name이 True인 경우)\n",
        " - reshape : reshape 여부를 나타냄\n",
        "#다른 사이트\n",
        "> server_model.layers\n",
        "> hidden_2 = server_model.layers[1]\n",
        "> hidden_2.name\n",
        "> server_model.get_layer('dense_19')\n",
        "> weights, biases = hidden_2.get_weights()\n",
        "> print(weights.shape)\n",
        "> print(biases.shape)\n",
        "> print(weights)\n",
        ">print(biases)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idx = np.argsort(y_train)\n",
        "temp_yval=[]\n",
        "for i in range(len(idx)):\n",
        "    temp_yval.append(idx[i][9])\n",
        "\n",
        "idx = np.argsort(temp_yval)\n",
        "\n",
        "x_train_sorted = x_train[idx]\n",
        "y_train_sorted = y_train[idx]\n",
        "yval_sorted = np.array(temp_yval)[idx]\n",
        "\n",
        "\n",
        "sorted_x_train=np.zeros((10,10000,28,28,1))\n",
        "print(x_train_sorted[yval_sorted == 0].shape)\n",
        "\n",
        "\n",
        "sorted_x_train[0] = x_train_sorted[yval_sorted == 0]\n",
        "sorted_x_train[1] = x_train_sorted[yval_sorted == 1]\n",
        "sorted_x_train[2] = x_train_sorted[yval_sorted == 2]\n",
        "sorted_x_train[3] = x_train_sorted[yval_sorted == 3]\n",
        "sorted_x_train[4] = x_train_sorted[yval_sorted == 4]\n",
        "sorted_x_train[5] = x_train_sorted[yval_sorted == 5]\n",
        "sorted_x_train[6] = x_train_sorted[yval_sorted == 6]\n",
        "sorted_x_train[7] = x_train_sorted[yval_sorted == 7]\n",
        "sorted_x_train[8] = x_train_sorted[yval_sorted == 8]\n",
        "sorted_x_train[9] = x_train_sorted[yval_sorted == 9]\n",
        "\n",
        "'''\n",
        "print(\"0 :\",len(sorted_x_train[0]),\"1 :\",len(sorted_x_train[1]),\"2 :\",len(sorted_x_train[2]),\"3 :\",len(sorted_x_train[3]),\"4 :\",len(sorted_x_train[4]),\"5 :\",len(sorted_x_train[5]),\n",
        "\"6 :\",len(sorted_x_train[6]),\"7 :\",len(sorted_x_train[7]),\"8 :\",len(sorted_x_train[8]),\"9 :\",len(sorted_x_train[9]))\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"x_train.shape: \",x_train.shape)\n",
        "print(\"y_train.shape: \",y_train.shape)\n",
        "print(\"idx.shape: \",idx.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

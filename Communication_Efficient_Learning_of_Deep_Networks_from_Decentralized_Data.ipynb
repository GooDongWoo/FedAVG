{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ll5B6dINCJLj"
      },
      "outputs": [],
      "source": [
        "# 먼저 텐서플로우 다운받고 mnist 다운받고 준비를 한다.\n",
        "# 2NN 모델을 설계한다. K는 2~3개 정도만 설정 1Epoch만 돌리고 !!!Weight를 Server로 보낸다.!!! 서버는 W_(t+1)=W_t - g_k    //Fed_SGD,\n",
        "# 나중에는 클라이언트에서 여러 epoch로 돌리고 Weight를 Server로 보낸다. 서버는 W_(t+1)=W_t - g_k // Fed_AVG\n",
        "# 당연히 Communication cost는 AVG가 적을 것, AVG가 정확성이 따라올 수 있느냐를 중점으로 확인.\n",
        "# 가장 먼저 서버모델을 만들고(이니셜라이징), 포문?(확실치 않은 이유가 포문 돌때마다 처음으로 초기화될까봐 겁남.)\n",
        "# 전체 포문 안에 클라이언트1,2 돌리고 그 2개의 w를 산술평균?(일단 나중에 가중산술평균할겨) 마지막에 서버 모델 w에 덮어씌우고\n",
        "# 근데 Non-IID 로 MNIST는 어떻게 나누지?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' 8/29 \\n    AVG로 구현하기 dd\\n    1round 마다 server가 클라이언트한테 나눠주기 구현 dd\\n    2NN말고 CNN으로 구현하기 dd\\n    MNIST 전부 분류하고 랜덤하게 몇개씩 뽑고 뽑을 때 겹치지 않게\\n    시각적으로 보이게 히스토그램?\\n    각 클라이언트들이 에포크 증가할때 정확도가 증가하는지?\\n    클라이언트가 N개일 때 자동화 어떻게 할 것인지..\\n    논문에서는 클라이언트가 100이다.\\n'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' 8/29 \n",
        "    AVG로 구현하기 dd\n",
        "    1round 마다 server가 클라이언트한테 나눠주기 구현 dd\n",
        "    2NN말고 CNN으로 구현하기 dd\n",
        "    MNIST 전부 분류하고 랜덤하게 몇개씩 뽑고 뽑을 때 겹치지 않게\n",
        "    시각적으로 보이게 히스토그램?\n",
        "    각 클라이언트들이 에포크 증가할때 정확도가 증가하는지?\n",
        "    클라이언트가 N개일 때 자동화 어떻게 할 것인지..\n",
        "    논문에서는 클라이언트가 100이다.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cnt0dhsmRZ_",
        "outputId": "18eea383-1e0e-43ae-a9d2-b3e350c78d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\python\\lib\\site-packages (3.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\python\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\python\\lib\\site-packages (from matplotlib) (9.3.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\python\\lib\\site-packages (from matplotlib) (6.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\python\\lib\\site-packages (from matplotlib) (1.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python\\lib\\site-packages (from matplotlib) (22.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\python\\lib\\site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python\\lib\\site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\python\\lib\\site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\python\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\python\\lib\\site-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\python\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.11.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 10, 10, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.22849, saving model to .\\MNIST_MLP_0.hdf5\n"
          ]
        }
      ],
      "source": [
        "%pip install matplotlib\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "client_num=100\n",
        "B_batch=200 # 배치 사이즈\n",
        "C_epoch=3  # 각 클라이언트마다 몇 에포크 돌릴지\n",
        "S_round=5  #총 라운드 수\n",
        "#\n",
        "#\n",
        "#데이터(MNIST) 전처리\n",
        "# MNIST 데이터를 불러옵니다.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# 차원 변환 후, 테스트셋과 학습셋으로 나눔\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "##서버 모델 이니셜라이징\n",
        "# 모델 구조를 설정\n",
        "\n",
        "server_model = Sequential()\n",
        "server_model.add(Conv2D(32, kernel_size=(5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "server_model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "server_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#server_model.add(Dropout(0.25))\n",
        "server_model.add(Flatten())\n",
        "server_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "#서버 레이어들 정보 요약\n",
        "server_model.summary()                                                \n",
        "\n",
        "# 모델 실행 환경을 설정\n",
        "server_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 최적화를 위한 설정 구간\n",
        "serverpath=\"./MNIST_MLP_0.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=serverpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# 모델 실행\n",
        "server_history = server_model.fit(x_train[0:2], y_train[0:2], validation_split=0.25, epochs=1, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer]) # 최대한 학습 안할려고 2개만 학습시킴..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_14 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 10, 10, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_22 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_28 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_32 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_34 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_36 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_38 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_19 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_42 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_21 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_44 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_22 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_46 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_23 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_48 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_24 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_50 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_25 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_52 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_26 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_54 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_55 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_27 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_56 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_28 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_58 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_29 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_60 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_30 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_62 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_31 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_64 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_32 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_66 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_33 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_68 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_34 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_70 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_35 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_72 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_36 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_74 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_75 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_37 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_76 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_77 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_38 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_78 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_79 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_39 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_80 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_81 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_40 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_82 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_83 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_41 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_84 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_85 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_42 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_42 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_86 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_87 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_43 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_43 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_88 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_89 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_44 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_44 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_90 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_91 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_45 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_45 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_92 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_93 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_46 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_46 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_94 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_95 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_47 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_47 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_96 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_48 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_48 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_98 (Conv2D)          (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_49 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_49 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_100 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_50 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_102 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_103 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_51 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_51 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_104 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_105 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_52 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_52 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_106 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_107 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_53 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_53 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_108 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_109 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_54 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_54 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_110 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_111 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_55 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_55 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_112 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_113 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_56 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_56 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_114 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_115 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_57 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_57 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_58\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_116 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_117 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_58 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_58 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_118 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_119 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_59 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_59 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_120 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_121 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_60 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_60 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_122 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_123 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_61 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_61 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_124 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_125 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_62 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_62 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_126 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_127 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_63 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_63 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_128 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_129 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_64 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_64 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_130 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_131 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_65 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_65 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_132 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_133 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_66 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_66 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_134 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_135 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_67 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_67 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_136 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_137 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_68 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_68 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_138 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_139 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_69 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_69 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_140 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_141 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_70 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_70 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_142 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_143 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_71 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_71 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_144 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_145 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_72 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_72 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_146 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_147 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_73 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_73 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_148 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_149 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_74 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_74 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_75\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_150 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_151 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_75 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_75 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_76\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_152 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_153 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_76 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_76 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_77\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_154 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_155 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_77 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_77 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_78\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_156 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_157 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_78 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_78 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_79\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_158 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_159 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_79 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_79 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_80\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_160 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_161 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_80 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_80 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_81\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_162 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_163 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_81 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_81 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_82\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_164 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_165 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_82 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_82 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_83\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_166 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_167 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_83 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_83 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_84\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_168 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_169 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_84 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_84 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_85\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_170 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_171 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_85 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_85 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_86\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_172 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_173 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_86 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_86 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_87\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_174 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_175 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_87 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_87 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_88\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_176 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_177 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_88 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_88 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_89\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_178 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_179 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_89 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_89 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_90\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_180 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_181 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_90 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_90 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_91\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_182 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_183 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_91 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_91 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_92\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_184 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_185 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_92 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_92 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_93\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_186 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_187 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_93 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_93 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_94\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_188 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_189 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_94 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_94 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_95\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_190 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_191 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_95 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_95 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_96\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_192 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_193 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_96 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_96 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_97\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_194 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_195 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_97 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_97 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_98\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_196 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_197 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_98 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_98 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_99\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_198 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_199 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_99 (MaxPoolin  (None, 10, 10, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_99 (Flatten)        (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n",
            "Model: \"sequential_100\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_200 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_201 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_100 (MaxPooli  (None, 10, 10, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_100 (Flatten)       (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "@@@@@@@@@@@@@@@@\n"
          ]
        }
      ],
      "source": [
        "#클라이언트 100명 각각 설정하는 것\n",
        "clients_model=[]\n",
        "clients_path=[]\n",
        "for i in range(client_num):\n",
        "    ##클라이언트i 모델 이니셜라이징\n",
        "    # 모델 구조를 설정\n",
        "    clients_model.append(Sequential()) \n",
        "    clients_model[i].add(Conv2D(32, kernel_size=(5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "    clients_model[i].add(Conv2D(64, (5, 5), activation='relu'))\n",
        "    clients_model[i].add(MaxPooling2D(pool_size=(2,2)))\n",
        "    #clients_model[i].add(Dropout(0.25))\n",
        "    clients_model[i].add(Flatten())\n",
        "    clients_model[i].add(Dense(10, activation='softmax'))\n",
        "    clients_model[i].summary()                                                #서버 레이어들 정보 요약\n",
        "    print(\"@@@@@@@@@@@@@@@@\")\n",
        "\n",
        "    # 모델 실행 환경을 설정\n",
        "    clients_model[i].compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    # 모델 최적화를 위한 설정 구간\n",
        "    clients_path.append(\"./MNIST_MLP_\"+str(i)+\".hdf5\")\n",
        "    checkpointer = ModelCheckpoint(filepath=clients_path[i], monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
        "\n",
        "    #처음 서버가 클라이언트한테 나눠주는 것\n",
        "    array_temp=server_model.get_weights()\n",
        "    clients_model[i].set_weights(array_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.09155, saving model to .\\MNIST_MLP_99.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.09155 to 1.68262, saving model to .\\MNIST_MLP_99.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.68262 to 1.12415, saving model to .\\MNIST_MLP_99.hdf5\n",
            "0th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 1.12415\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.12415\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.12415\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 1.12415\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.12415\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.12415 to 1.02726, saving model to .\\MNIST_MLP_99.hdf5\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000132BD707E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 1.02726\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.02726\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.02726 to 0.95147, saving model to .\\MNIST_MLP_99.hdf5\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000132BD84DD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.95147\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.95147\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.95147 to 0.93189, saving model to .\\MNIST_MLP_99.hdf5\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "10th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "20th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "30th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.93189\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.93189 to 0.77718, saving model to .\\MNIST_MLP_99.hdf5\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "40th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "50th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "60th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "70th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "80th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "90th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.1804 - accuracy: 0.7758\n",
            "6th Test Accuracy: 0.7758\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 1.2589 - accuracy: 0.7652\n",
            "6th Train Accuracy: 0.7652\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "0th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.77718\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.77718 to 0.76247, saving model to .\\MNIST_MLP_99.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.76247 to 0.61949, saving model to .\\MNIST_MLP_99.hdf5\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.61949\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.61949\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.61949 to 0.50189, saving model to .\\MNIST_MLP_99.hdf5\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "10th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "20th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.50189\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.50189 to 0.43966, saving model to .\\MNIST_MLP_99.hdf5\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.43966\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.43966\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.43966\n",
            "30th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.43966\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.43966\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.43966\n",
            "\n",
            "Epoch 00001: val_loss improved from 0.43966 to 0.27630, saving model to .\\MNIST_MLP_99.hdf5\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.27630\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.27630 to 0.19404, saving model to .\\MNIST_MLP_99.hdf5\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "40th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "50th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "60th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "70th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "80th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "90th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 5.2154 - accuracy: 0.8544\n",
            "6th Test Accuracy: 0.8544\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 5.4424 - accuracy: 0.8510\n",
            "6th Train Accuracy: 0.8510\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "0th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "10th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "20th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "30th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "40th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "50th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "60th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "70th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "80th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "90th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 27.3218 - accuracy: 0.8770\n",
            "6th Test Accuracy: 0.8770\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 28.6782 - accuracy: 0.8692\n",
            "6th Train Accuracy: 0.8692\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "0th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "10th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "20th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "30th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "40th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "50th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "60th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "70th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "80th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "90th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 182.2247 - accuracy: 0.8815\n",
            "6th Test Accuracy: 0.8815\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 192.6650 - accuracy: 0.8751\n",
            "6th Train Accuracy: 0.8751\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "0th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "10th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "20th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "30th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "40th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "50th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "60th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "70th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "80th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "90th client is studying\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.19404\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.19404\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1253.5486 - accuracy: 0.8859\n",
            "6th Test Accuracy: 0.8859\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 1331.4005 - accuracy: 0.8805\n",
            "6th Train Accuracy: 0.8805\n"
          ]
        }
      ],
      "source": [
        "#100명의 클라이언트 w를 산술평균해서 서버 w에 덮어 씌우기.\n",
        "history_temp=[[],[]]\n",
        "clients_history=[]\n",
        "for i in range(0,S_round): #per round\n",
        "    #각 클라이언트들마다 computations\n",
        "    for j in range(client_num):#아직은 샤드2개가 아닌 300크기*2씩 준다..원래는 300짜리 다른 숫자라벨2개를 100명한테 주는거다.\n",
        "        clients_history.append(clients_model[j].fit(x_train[300*2*(j):300*2*(j+1)], y_train[300*2*(j):300*2*(j+1)], validation_split=0.25, epochs=C_epoch, batch_size=B_batch, verbose=0, callbacks=[early_stopping_callback,checkpointer]) )\n",
        "        if j%10==0:\n",
        "            print(str(j)+\"th client is studying\")\n",
        "        #client_2_history = client_2_model.fit(x_train[10000:20000], y_train[10000:20000], validation_split=0.25, epochs=C_epoch, batch_size=B_batch, verbose=0, callbacks=[early_stopping_callback,checkpointer]) \n",
        "    \n",
        "    #각 클라이언트들의 w를 산술평균해서 서버에다가 주는 과정  \n",
        "    array_temp = []\n",
        "    for i in range(len(clients_model[0].get_weights())):\n",
        "        array_temp.append(clients_model[0].get_weights()[i])\n",
        "        for j in range(1,client_num):\n",
        "            array_temp[i]+=(clients_model[j].get_weights()[i])/client_num\n",
        "    server_model.set_weights(array_temp)\n",
        "\n",
        "    #1round마다 서버에 모여진 w를 다시 클라이언트한테 주는 것\n",
        "    for j in range(client_num):\n",
        "        clients_model[j].set_weights(array_temp)\n",
        "\n",
        "    #서버의 1round마다의 데이터들의 히스토리를 모으는 과정\n",
        "    history_temp[1].append(server_model.evaluate(x_test, y_test)[1])\n",
        "    print(str(i+1)+\"th Test Accuracy: %.4f\" % (history_temp[-1][-1]))\n",
        "    history_temp[0].append(server_model.evaluate(x_train[0:20000], y_train[0:20000])[1])\n",
        "    print(str(i+1)+\"th Train Accuracy: %.4f\" % (history_temp[0][-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "US9iJu4rlKDz",
        "outputId": "41927ab2-e6cf-48d2-e1ab-b09d3d211921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 1253.5486 - accuracy: 0.8859\n",
            "\n",
            " Test Accuracy: 0.8859\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 테스트 정확도\n",
        "print(\"\\n Test Accuracy: %.4f\" % (server_model.evaluate(x_test, y_test)[1]))\n",
        "# 검증셋과 학습셋의 오차를 저장\n",
        "y_vloss = history_temp[1] #server_history.history['val_loss']\n",
        "y_loss = history_temp[0]  #server_history.history['loss']\n",
        "\n",
        "# 그래프로 표현\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
        "\n",
        "# 그래프에 그리드, 레이블\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('round')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#keras model에서 가중치(weights) 가져오기\n",
        "\n",
        ">`Model.get_weights()`\n",
        "\n",
        "return:모델의 가중치 배열\n",
        "\n",
        "#Keras model에 가중치(weights) 설정하기\n",
        ">`Model.set_weights(weights)`\n",
        "\n",
        "argument:\n",
        " - weights : numpy 배열의 가중치\n",
        "\n",
        "#Keras model의 가중치(weights) 파일로 저장하기\n",
        ">`Model.save_weights(filepath, overwrite=True)`\n",
        "\n",
        "arguments:\n",
        " - filepath : 저장할 파일 경로, HDF5 형식으로 저장된다.\n",
        " - overwrite : 덮어쓰기 여부\n",
        "\n",
        "#파일에서 Keras model 가중치(weights) 불러와 설정하기\n",
        "> `Model.load_weights(filepath, by_name=False, skip_mismatch=False, reshpae=False)`\n",
        "\n",
        "arguments:\n",
        " - filepath : 가중치 파일의 경로\n",
        " - by_name : 이름 또는 토폴로지 순서로 가중치를 로드 할지 여부를 나타낸다.\n",
        " - skip_mismath : 가중치 개수나 모양이 일치하지 않는 레이어를 건너 뛸지에 대한 여부를 나타낸다. (by_name이 True인 경우)\n",
        " - reshape : reshape 여부를 나타냄\n",
        "#다른 사이트\n",
        "> server_model.layers\n",
        "> hidden_2 = server_model.layers[1]\n",
        "> hidden_2.name\n",
        "> server_model.get_layer('dense_19')\n",
        "> weights, biases = hidden_2.get_weights()\n",
        "> print(weights.shape)\n",
        "> print(biases.shape)\n",
        "> print(weights)\n",
        ">print(biases)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nprint(\"0 :\",len(sorted_x_train[0]),\"1 :\",len(sorted_x_train[1]),\"2 :\",len(sorted_x_train[2]),\"3 :\",len(sorted_x_train[3]),\"4 :\",len(sorted_x_train[4]),\"5 :\",len(sorted_x_train[5]),\\n\"6 :\",len(sorted_x_train[6]),\"7 :\",len(sorted_x_train[7]),\"8 :\",len(sorted_x_train[8]),\"9 :\",len(sorted_x_train[9]))\\n\\nprint(x_train_sorted[yval_sorted == 0].shape)\\n'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx = np.argsort(y_train) #idx는 \n",
        "temp_yval=[]\n",
        "for i in range(len(idx)):\n",
        "    temp_yval.append(idx[i][9])\n",
        "\n",
        "idx = np.argsort(temp_yval)\n",
        "\n",
        "x_train_sorted = x_train[idx]\n",
        "y_train_sorted = y_train[idx]\n",
        "yval_sorted = np.array(temp_yval)[idx]\n",
        "\n",
        "sorted_x_train=[]\n",
        "#sorted_x_train=np.array(sorted_x_train)\n",
        "for i in range(10):\n",
        "    sorted_x_train.append(x_train_sorted[yval_sorted == i])\n",
        "\n",
        "'''\n",
        "print(\"0 :\",len(sorted_x_train[0]),\"1 :\",len(sorted_x_train[1]),\"2 :\",len(sorted_x_train[2]),\"3 :\",len(sorted_x_train[3]),\"4 :\",len(sorted_x_train[4]),\"5 :\",len(sorted_x_train[5]),\n",
        "\"6 :\",len(sorted_x_train[6]),\"7 :\",len(sorted_x_train[7]),\"8 :\",len(sorted_x_train[8]),\"9 :\",len(sorted_x_train[9]))\n",
        "\n",
        "print(x_train_sorted[yval_sorted == 0].shape)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train.shape:  (60000, 28, 28, 1)\n",
            "y_train.shape:  (60000, 10)\n",
            "idx.shape:  (60000,)\n"
          ]
        }
      ],
      "source": [
        "print(\"x_train.shape: \",x_train.shape)\n",
        "print(\"y_train.shape: \",y_train.shape)\n",
        "print(\"idx.shape: \",idx.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_101\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_202 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_203 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_101 (MaxPooli  (None, 10, 10, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_101 (Flatten)       (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "##클라이언트1 모델 이니셜라이징\n",
        "# 모델 구조를 설정\n",
        "\n",
        "\n",
        "client_1_model = Sequential()\n",
        "client_1_model.add(Conv2D(32, kernel_size=(5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "client_1_model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "client_1_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#client_1_model.add(Dropout(0.25))\n",
        "client_1_model.add(Flatten())\n",
        "client_1_model.add(Dense(10, activation='softmax'))\n",
        "client_1_model.summary()                                                #서버 레이어들 정보 요약\n",
        "\n",
        "# 모델 실행 환경을 설정\n",
        "client_1_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 최적화를 위한 설정 구간\n",
        "client_1path=\"./MNIST_MLP_1.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=client_1path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "#처음 서버가 클라이언트한테 나눠주는 것\n",
        "array_temp=server_model.get_weights()\n",
        "client_1_model.set_weights(array_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_102\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_204 (Conv2D)         (None, 24, 24, 32)        832       \n",
            "                                                                 \n",
            " conv2d_205 (Conv2D)         (None, 20, 20, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_102 (MaxPooli  (None, 10, 10, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_102 (Flatten)       (None, 6400)              0         \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 10)                64010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116,106\n",
            "Trainable params: 116,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "##클라이언트2 모델 이니셜라이징\n",
        "# 모델 구조를 설정\n",
        "client_2_model = Sequential()\n",
        "client_2_model.add(Conv2D(32, kernel_size=(5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "client_2_model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "client_2_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#client_2_model.add(Dropout(0.25))\n",
        "client_2_model.add(Flatten())\n",
        "client_2_model.add(Dense(10, activation='softmax'))\n",
        "client_2_model.summary()    #서버 레이어들 정보 요약\n",
        "\n",
        "# 모델 실행 환경을 설정\n",
        "client_2_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 모델 최적화를 위한 설정 구간\n",
        "client_2path=\"./MNIST_MLP_2.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=client_2path, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "\n",
        "#처음 서버가 클라이언트한테 나눠주는 것\n",
        "array_temp=server_model.get_weights()\n",
        "client_2_model.set_weights(array_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 1095.69958, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 1095.69958 to 873.03839, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 873.03839 to 711.93951, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 711.93951\n",
            "\n",
            "Epoch 00002: val_loss improved from 711.93951 to 675.51758, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 675.51758 to 544.40747, saving model to .\\MNIST_MLP_2.hdf5\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 574.3046 - accuracy: 0.9150\n",
            "6th Test Accuracy: 0.9150\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 590.8555 - accuracy: 0.9111\n",
            "6th Train Accuracy: 0.9111\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 544.40747\n",
            "\n",
            "Epoch 00002: val_loss improved from 544.40747 to 499.30511, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 499.30511 to 432.34274, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 432.34274\n",
            "\n",
            "Epoch 00002: val_loss improved from 432.34274 to 386.04651, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 386.04651 to 324.93393, saving model to .\\MNIST_MLP_2.hdf5\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 345.7598 - accuracy: 0.9252\n",
            "6th Test Accuracy: 0.9252\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 338.5405 - accuracy: 0.9257\n",
            "6th Train Accuracy: 0.9257\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 324.93393\n",
            "\n",
            "Epoch 00002: val_loss improved from 324.93393 to 321.62949, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 321.62949 to 294.57224, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00001: val_loss improved from 294.57224 to 286.51907, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 286.51907 to 246.93111, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 246.93111 to 219.01445, saving model to .\\MNIST_MLP_2.hdf5\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 225.0636 - accuracy: 0.9323\n",
            "6th Test Accuracy: 0.9323\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 214.7125 - accuracy: 0.9348\n",
            "6th Train Accuracy: 0.9348\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 219.01445\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 219.01445\n",
            "\n",
            "Epoch 00003: val_loss improved from 219.01445 to 208.03764, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00001: val_loss improved from 208.03764 to 190.41907, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 190.41907 to 171.08791, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 171.08791 to 151.72485, saving model to .\\MNIST_MLP_2.hdf5\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 156.5895 - accuracy: 0.9392\n",
            "6th Test Accuracy: 0.9392\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 145.0357 - accuracy: 0.9430\n",
            "6th Train Accuracy: 0.9430\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 151.72485\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 151.72485\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 151.72485\n",
            "\n",
            "Epoch 00001: val_loss improved from 151.72485 to 139.33150, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00002: val_loss improved from 139.33150 to 123.97599, saving model to .\\MNIST_MLP_2.hdf5\n",
            "\n",
            "Epoch 00003: val_loss improved from 123.97599 to 112.75575, saving model to .\\MNIST_MLP_2.hdf5\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 115.4105 - accuracy: 0.9458\n",
            "6th Test Accuracy: 0.9458\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 102.8819 - accuracy: 0.9499\n",
            "6th Train Accuracy: 0.9499\n"
          ]
        }
      ],
      "source": [
        "#클라이언트 2명의 w를 산술평균해서 서버 w에 덮어 씌우기.\n",
        "\n",
        "\n",
        "history_temp=[[],[]]\n",
        "\n",
        "for i in range(0,S_round):\n",
        "  #각 클라이언트들마다 computations\n",
        "  client_1_history = client_1_model.fit(x_train[0:10000], y_train[0:10000], validation_split=0.25, epochs=C_epoch, batch_size=B_batch, verbose=0, callbacks=[early_stopping_callback,checkpointer]) \n",
        "  client_2_history = client_2_model.fit(x_train[10000:20000], y_train[10000:20000], validation_split=0.25, epochs=C_epoch, batch_size=B_batch, verbose=0, callbacks=[early_stopping_callback,checkpointer]) \n",
        "  \n",
        "  #각 클라이언트들의 w를 산술평균해서 서버에다가 주는 과정  \n",
        "  array_temp = []\n",
        "  for i in range(len(client_1_model.get_weights())):\n",
        "      array_temp.append((client_1_model.get_weights()[i]+(client_2_model.get_weights())[i])/2.0)\n",
        "  server_model.set_weights(array_temp)\n",
        "  \n",
        "  #1round마다 서버에 모여진 w를 다시 클라이언트한테 주는 것\n",
        "  array_temp=server_model.get_weights()\n",
        "  client_1_model.set_weights(array_temp)\n",
        "  client_2_model.set_weights(array_temp)\n",
        "\n",
        "  #서버의 1round마다의 데이터들의 히스토리를 모으는 과정\n",
        "  history_temp[1].append(server_model.evaluate(x_test, y_test)[1])\n",
        "  print(str(i+1)+\"th Test Accuracy: %.4f\" % (history_temp[-1][-1]))\n",
        "  history_temp[0].append(server_model.evaluate(x_train[0:20000], y_train[0:20000])[1])\n",
        "  print(str(i+1)+\"th Train Accuracy: %.4f\" % (history_temp[0][-1]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
